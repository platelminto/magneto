{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955a6ddc",
   "metadata": {},
   "source": [
    "# EEG Signal Classification using GRU Models\n",
    "\n",
    "In this notebook, we explore the application of Gated Recurrent Unit (GRU) models to classify EEG signals. We will work with two types of datasets: INTRA and CROSS. Our objective is to build, train, and evaluate standard and advanced GRU models, the latter incorporating attention mechanisms, to determine their efficacy in EEG signal classification tasks:)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aec487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout, TimeDistributed\n",
    "\n",
    "\n",
    "data_dir = Path(\"./data/\")\n",
    "intra_dir = data_dir / \"Intra\"\n",
    "cross_dir = data_dir / \"Cross\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2e277",
   "metadata": {},
   "source": [
    "## Data loading & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc63c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(path):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        keys = list(f.keys())\n",
    "        assert len(keys) == 1, \"Only one key per file is expected\"\n",
    "        matrix = f[keys[0]][()]\n",
    "    return matrix\n",
    "\n",
    "def load_labels(path: Path) -> np.ndarray:\n",
    "    *task, subject_identifier, chunk = path.stem.split(\"_\")\n",
    "    if \"rest\" in task:\n",
    "        y = 0\n",
    "    elif 'math' in task:\n",
    "        y = 1\n",
    "    elif 'working' in task:\n",
    "        y = 2\n",
    "    elif 'motor' in task:\n",
    "        y = 3\n",
    "    else:\n",
    "        assert False, 'unknown task'\n",
    "    return np.array([y, int(subject_identifier), int(chunk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee48c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, old_freq, new_freq):\n",
    "    # Calculate the downsampling factor\n",
    "    downsample_factor = int(np.round(old_freq / new_freq))\n",
    "    # Ensure that timesteps are divisible by the downsampling factor\n",
    "    data = data[:,:,:data.shape[2]//downsample_factor*downsample_factor]\n",
    "    # Reshape\n",
    "    reshaped_data = data.reshape(data.shape[0], data.shape[1], -1, downsample_factor)\n",
    "    # Take the mean along the last axis\n",
    "    downsampled_data = reshaped_data.mean(axis=-1)\n",
    "    return downsampled_data\n",
    "\n",
    "def z_score_normalize(data):\n",
    "    # Convert to PyTorch tensor\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    # Calculate mean and std along the timesteps\n",
    "    mean = torch.mean(data_tensor, dim=2, keepdim=True)\n",
    "    std = torch.std(data_tensor, dim=2, keepdim=True)\n",
    "    # Perform z-score norm\n",
    "    normalized_data = (data_tensor - mean) / std\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d587add0",
   "metadata": {},
   "source": [
    "### INTRA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6648dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INTRA Data Loading and Preprocessing\n",
    "\n",
    "intra_train_glob = list((intra_dir / \"train\").glob(\"*.h5\"))\n",
    "intra_test_glob = list((intra_dir / \"test\").glob(\"*.h5\"))\n",
    "intra_train_X = np.stack([load_h5(path) for path in intra_train_glob])\n",
    "intra_train_labels = np.array([load_labels(path)[0] for path in intra_train_glob])\n",
    "intra_test_X = np.stack([load_h5(path) for path in intra_test_glob])\n",
    "intra_test_labels = np.array([load_labels(path)[0] for path in intra_test_glob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ff410c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "intra_train_X_downsampled = downsample(intra_train_X, 2034, 125)\n",
    "intra_train_X_norm = z_score_normalize(intra_train_X_downsampled)\n",
    "\n",
    "intra_test_X_downsampled = downsample(intra_test_X, 2034, 125)\n",
    "intra_test_X_norm = z_score_normalize(intra_test_X_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff1c838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 248, 2226)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intra_train_X_preprocessed = intra_train_X_norm.numpy()\n",
    "intra_train_X_preprocessed.shape\n",
    "intra_test_X_preprocessed = intra_test_X_norm.numpy()\n",
    "intra_test_X_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b6aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4  \n",
    "intra_train_labels_one_hot = to_categorical(intra_train_labels, num_classes)\n",
    "intra_test_labels_one_hot = to_categorical(intra_test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae98d3",
   "metadata": {},
   "source": [
    "### CROSS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6992e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_train_glob = list((cross_dir / \"train\").glob(\"*.h5\")) + list((cross_dir / \"test1\").glob(\"*.h5\")) + list((cross_dir / \"test2\").glob(\"*.h5\"))\n",
    "cross_test_glob = list((cross_dir / \"test3\").glob(\"*.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9de5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_train_X = np.stack([load_h5(path) for path in cross_train_glob])\n",
    "cross_train_labels = np.array([load_labels(path)[0] for path in cross_train_glob])\n",
    "\n",
    "cross_test_X = np.stack([load_h5(path) for path in cross_test_glob])\n",
    "cross_test_labels = np.array([load_labels(path)[0] for path in cross_test_glob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4422e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Cross data\n",
    "cross_train_X_downsampled = downsample(cross_train_X, 2034, 125)\n",
    "cross_train_X_norm = z_score_normalize(cross_train_X_downsampled)\n",
    "\n",
    "cross_test_X_downsampled = downsample(cross_test_X, 2034, 125)\n",
    "cross_test_X_norm = z_score_normalize(cross_test_X_downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e59551",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_train_X_norm = cross_train_X_norm.numpy()\n",
    "cross_test_X_norm = cross_test_X_norm.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213cb962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical\n",
    "cross_train_labels_cat = to_categorical(cross_train_labels)\n",
    "cross_test_labels_cat = to_categorical(cross_test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb5d00",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "We will define two GRU-based models: a standard GRU model and an advanced GRU model with attention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed6989cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gru_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(GRU(64))\n",
    "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df99d14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name='attention_weight', \n",
    "                                 shape=(input_shape[-1], 1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        self.b = self.add_weight(name='attention_bias',\n",
    "                                 shape=(input_shape[1], 1),\n",
    "                                 initializer='zeros',\n",
    "                                 trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        # Alignment scores. Shape: [batch_size, time_steps]\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        e = K.squeeze(e, axis=-1)\n",
    "\n",
    "        # Softmax over alignment scores to get attention weights\n",
    "        alpha = K.softmax(e)\n",
    "\n",
    "        # Context vector is the weighted sum of the inputs\n",
    "        context = x * K.expand_dims(alpha, -1)\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c1569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_advanced_gru_model_with_attention(input_shape, num_classes=4):\n",
    "    model = Sequential([\n",
    "        Bidirectional(GRU(128, return_sequences=True), input_shape=input_shape),\n",
    "        Dropout(0.5),\n",
    "        Bidirectional(GRU(64, return_sequences=True)),  # Keep return_sequences=True\n",
    "        AttentionLayer(),  # Custom attention layer\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3df5320",
   "metadata": {},
   "source": [
    "## Model traning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eafc13",
   "metadata": {},
   "source": [
    "### Intra traing with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "106b819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2df112f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.5108 - accuracy: 0.3200 - val_loss: 2.1034 - val_accuracy: 0.1429\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.4893 - accuracy: 0.8800 - val_loss: 2.0623 - val_accuracy: 0.1429\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 541ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 2.0419 - val_accuracy: 0.1429\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 525ms/step - loss: 0.0742 - accuracy: 1.0000 - val_loss: 2.0700 - val_accuracy: 0.1429\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 527ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 2.1182 - val_accuracy: 0.1429\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 564ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.1715 - val_accuracy: 0.1429\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.2224 - val_accuracy: 0.2857\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.2682 - val_accuracy: 0.1429\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 538ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.3078 - val_accuracy: 0.1429\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 539ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.3417 - val_accuracy: 0.2857\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1.5261 - accuracy: 0.2800 - val_loss: 1.4390 - val_accuracy: 0.2857\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 982ms/step - loss: 1.2484 - accuracy: 0.4000 - val_loss: 1.5143 - val_accuracy: 0.2857\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 974ms/step - loss: 1.0798 - accuracy: 0.6400 - val_loss: 1.6660 - val_accuracy: 0.1429\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9062 - accuracy: 0.6800 - val_loss: 1.7576 - val_accuracy: 0.1429\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7670 - accuracy: 0.8000 - val_loss: 1.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6352 - accuracy: 0.8000 - val_loss: 1.8786 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6645 - accuracy: 0.6800 - val_loss: 1.8477 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5314 - accuracy: 0.8400 - val_loss: 1.8441 - val_accuracy: 0.1429\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4506 - accuracy: 0.9200 - val_loss: 1.8756 - val_accuracy: 0.1429\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4712 - accuracy: 0.8400 - val_loss: 1.9380 - val_accuracy: 0.1429\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.3694 - accuracy: 0.2400 - val_loss: 1.3891 - val_accuracy: 0.4286\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 530ms/step - loss: 0.3459 - accuracy: 0.9600 - val_loss: 1.2223 - val_accuracy: 0.2857\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 542ms/step - loss: 0.1160 - accuracy: 1.0000 - val_loss: 1.1400 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 552ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 1.1186 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.1147 - val_accuracy: 0.4286\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.1161 - val_accuracy: 0.4286\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.1199 - val_accuracy: 0.4286\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 1.1257 - val_accuracy: 0.4286\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 560ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.1332 - val_accuracy: 0.4286\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1421 - val_accuracy: 0.4286\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 8s 8s/step - loss: 1.4355 - accuracy: 0.1600 - val_loss: 1.4657 - val_accuracy: 0.2857\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1793 - accuracy: 0.4400 - val_loss: 1.3595 - val_accuracy: 0.1429\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.9851 - accuracy: 0.6400 - val_loss: 1.3416 - val_accuracy: 0.2857\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.8210 - accuracy: 0.8000 - val_loss: 1.3111 - val_accuracy: 0.2857\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6978 - accuracy: 0.8800 - val_loss: 1.1899 - val_accuracy: 0.2857\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6283 - accuracy: 0.7600 - val_loss: 1.1077 - val_accuracy: 0.4286\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4813 - accuracy: 0.9600 - val_loss: 1.0341 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.3510 - accuracy: 0.9600 - val_loss: 1.0215 - val_accuracy: 0.5714\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4973 - accuracy: 0.8400 - val_loss: 1.0161 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.5055 - accuracy: 0.9200 - val_loss: 1.0024 - val_accuracy: 0.5714\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.5309 - accuracy: 0.1923 - val_loss: 1.3905 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 520ms/step - loss: 0.4763 - accuracy: 0.9231 - val_loss: 1.5334 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 531ms/step - loss: 0.1548 - accuracy: 1.0000 - val_loss: 1.6759 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 522ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.7839 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 1.8608 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 533ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.9181 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 540ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.9647 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 532ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.0059 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 570ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 2.0439 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 2.0791 - val_accuracy: 0.5000\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.4799 - accuracy: 0.1923 - val_loss: 1.4587 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3482 - accuracy: 0.4231 - val_loss: 1.6177 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.0149 - accuracy: 0.4231 - val_loss: 1.5594 - val_accuracy: 0.3333\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.9820 - accuracy: 0.6154 - val_loss: 1.5586 - val_accuracy: 0.3333\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7089 - accuracy: 0.7692 - val_loss: 1.5242 - val_accuracy: 0.3333\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6928 - accuracy: 0.7308 - val_loss: 1.5691 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7040 - accuracy: 0.6923 - val_loss: 1.6141 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4910 - accuracy: 0.8462 - val_loss: 1.6968 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 0.4711 - accuracy: 0.8462 - val_loss: 1.7597 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4645 - accuracy: 0.8846 - val_loss: 1.8020 - val_accuracy: 0.3333\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.5585 - accuracy: 0.1538 - val_loss: 1.7687 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.4284 - accuracy: 0.9615 - val_loss: 2.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.1698 - accuracy: 1.0000 - val_loss: 2.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0842 - accuracy: 1.0000 - val_loss: 2.3248 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 2.3981 - val_accuracy: 0.1667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 2.4619 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.5225 - val_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.5813 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.6388 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.6948 - val_accuracy: 0.1667\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1.4639 - accuracy: 0.2692 - val_loss: 1.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.1643 - accuracy: 0.5000 - val_loss: 1.7337 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.0721 - accuracy: 0.5000 - val_loss: 1.7628 - val_accuracy: 0.1667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7622 - accuracy: 0.6923 - val_loss: 1.7301 - val_accuracy: 0.1667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.8751 - accuracy: 0.6538 - val_loss: 1.8315 - val_accuracy: 0.1667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.7429 - accuracy: 0.6154 - val_loss: 1.9646 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5851 - accuracy: 0.8846 - val_loss: 2.0146 - val_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5623 - accuracy: 0.9231 - val_loss: 2.0842 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4951 - accuracy: 0.8462 - val_loss: 2.1894 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3981 - accuracy: 0.9231 - val_loss: 2.2893 - val_accuracy: 0.1667\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.4946 - accuracy: 0.2308 - val_loss: 1.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4137 - accuracy: 0.8846 - val_loss: 1.9163 - val_accuracy: 0.1667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.1570 - accuracy: 1.0000 - val_loss: 2.0861 - val_accuracy: 0.1667\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0861 - accuracy: 1.0000 - val_loss: 2.2489 - val_accuracy: 0.1667\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 2.3913 - val_accuracy: 0.1667\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 2.5151 - val_accuracy: 0.1667\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 2.6235 - val_accuracy: 0.1667\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.7184 - val_accuracy: 0.1667\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.8019 - val_accuracy: 0.1667\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.8756 - val_accuracy: 0.1667\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 14s 14s/step - loss: 1.4131 - accuracy: 0.2692 - val_loss: 1.6587 - val_accuracy: 0.3333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 1.3037 - accuracy: 0.4615 - val_loss: 1.6273 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.9493 - accuracy: 0.7308 - val_loss: 1.6295 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.9211 - accuracy: 0.5769 - val_loss: 1.6482 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6899 - accuracy: 0.7308 - val_loss: 1.6944 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6286 - accuracy: 0.8077 - val_loss: 1.7158 - val_accuracy: 0.3333\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4641 - accuracy: 0.8462 - val_loss: 1.7571 - val_accuracy: 0.3333\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4444 - accuracy: 0.8077 - val_loss: 1.8097 - val_accuracy: 0.3333\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.5580 - accuracy: 0.8077 - val_loss: 1.8893 - val_accuracy: 0.3333\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.4503 - accuracy: 0.9231 - val_loss: 1.9602 - val_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "for train, val in kfold.split(intra_train_X_preprocessed, intra_train_labels_one_hot):\n",
    "    # Build models for each fold\n",
    "    model_gru = build_gru_model(intra_train_X_preprocessed.shape[1:], 4)\n",
    "    model_advanced_gru = build_advanced_gru_model_with_attention(intra_train_X_preprocessed.shape[1:], 4)\n",
    "    \n",
    "    # Training\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history_gru = model_gru.fit(intra_train_X_preprocessed[train], intra_train_labels_one_hot[train], epochs=10, batch_size=32, validation_data=(intra_train_X_preprocessed[val], intra_train_labels_one_hot[val]))\n",
    "    history_advanced_gru = model_advanced_gru.fit(intra_train_X_preprocessed[train], intra_train_labels_one_hot[train], epochs=10, batch_size=32, validation_data=(intra_train_X_preprocessed[val], intra_train_labels_one_hot[val]))\n",
    "    \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7db2e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 674ms/step - loss: 1.6172 - accuracy: 0.3750\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.8650 - accuracy: 0.0000e+00\n",
      "Standard GRU Model Performance: [1.6172165870666504, 0.375]\n",
      "Advanced GRU Model with Attention Performance: [1.8650151491165161, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "performance_gru = model_gru.evaluate(intra_test_X_preprocessed, intra_test_labels_one_hot)\n",
    "performance_advanced_gru = model_advanced_gru.evaluate(intra_test_X_preprocessed, intra_test_labels_one_hot)\n",
    "\n",
    "print(\"Standard GRU Model Performance:\", performance_gru)\n",
    "print(\"Advanced GRU Model with Attention Performance:\", performance_advanced_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9313ea5b",
   "metadata": {},
   "source": [
    "### Cross training with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0481e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 2s/step - loss: 1.5183 - accuracy: 0.3026 - val_loss: 1.5960 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5846 - accuracy: 0.7895 - val_loss: 1.5099 - val_accuracy: 0.1500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3150 - accuracy: 0.9474 - val_loss: 1.3672 - val_accuracy: 0.4500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2067 - accuracy: 0.9868 - val_loss: 1.3457 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1214 - accuracy: 1.0000 - val_loss: 1.3940 - val_accuracy: 0.3000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0780 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.2500\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 1.4474 - val_accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0344 - accuracy: 1.0000 - val_loss: 1.4337 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 1.4250 - val_accuracy: 0.4500\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.4213 - val_accuracy: 0.5000\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 21s 5s/step - loss: 1.4484 - accuracy: 0.3026 - val_loss: 1.4012 - val_accuracy: 0.1500\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.2721 - accuracy: 0.3816 - val_loss: 1.3776 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.2024 - accuracy: 0.4342 - val_loss: 1.3265 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.0206 - accuracy: 0.6316 - val_loss: 1.3114 - val_accuracy: 0.3500\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 1.1085 - accuracy: 0.4868 - val_loss: 1.2873 - val_accuracy: 0.3500\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.8460 - accuracy: 0.6184 - val_loss: 1.3203 - val_accuracy: 0.3500\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.7427 - accuracy: 0.8158 - val_loss: 1.4382 - val_accuracy: 0.3000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.7441 - accuracy: 0.7632 - val_loss: 1.5962 - val_accuracy: 0.2500\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.7472 - accuracy: 0.7632 - val_loss: 1.6502 - val_accuracy: 0.2500\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.5580 - accuracy: 0.8421 - val_loss: 1.5395 - val_accuracy: 0.2500\n",
      "Training for fold 2 ...\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.4587 - accuracy: 0.2857 - val_loss: 1.3322 - val_accuracy: 0.5263\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.5025 - accuracy: 0.9221 - val_loss: 1.4381 - val_accuracy: 0.4211\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2580 - accuracy: 0.9870 - val_loss: 1.6164 - val_accuracy: 0.4211\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.1590 - accuracy: 0.9740 - val_loss: 1.8481 - val_accuracy: 0.3158\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.0925 - accuracy: 1.0000 - val_loss: 1.9139 - val_accuracy: 0.3158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 7s 3s/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 1.9828 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0368 - accuracy: 1.0000 - val_loss: 2.0177 - val_accuracy: 0.3158\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.0426 - val_accuracy: 0.3158\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 2.0697 - val_accuracy: 0.3158\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.3158\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 21s 6s/step - loss: 1.4257 - accuracy: 0.2338 - val_loss: 1.4025 - val_accuracy: 0.2632\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.1461 - accuracy: 0.5195 - val_loss: 1.4195 - val_accuracy: 0.2632\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.1492 - accuracy: 0.5195 - val_loss: 1.2262 - val_accuracy: 0.3684\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.9211 - accuracy: 0.6104 - val_loss: 1.2317 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.7914 - accuracy: 0.7143 - val_loss: 1.4084 - val_accuracy: 0.3158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.6950 - accuracy: 0.8052 - val_loss: 1.4843 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.5887 - accuracy: 0.7922 - val_loss: 1.6482 - val_accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.5633 - accuracy: 0.8182 - val_loss: 1.6014 - val_accuracy: 0.4211\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.4512 - accuracy: 0.8571 - val_loss: 1.5092 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.4335 - accuracy: 0.8831 - val_loss: 1.5993 - val_accuracy: 0.3684\n",
      "Training for fold 3 ...\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 11s 3s/step - loss: 1.4708 - accuracy: 0.2987 - val_loss: 1.3735 - val_accuracy: 0.4737\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.5003 - accuracy: 0.8701 - val_loss: 1.3492 - val_accuracy: 0.3684\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2767 - accuracy: 0.9740 - val_loss: 1.3677 - val_accuracy: 0.4737\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.1496 - accuracy: 1.0000 - val_loss: 1.3732 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0945 - accuracy: 1.0000 - val_loss: 1.3943 - val_accuracy: 0.4211\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 1.4152 - val_accuracy: 0.4211\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0401 - accuracy: 1.0000 - val_loss: 1.4561 - val_accuracy: 0.3684\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.5107 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.5294 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.5278 - val_accuracy: 0.3684\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 21s 6s/step - loss: 1.4993 - accuracy: 0.2208 - val_loss: 1.3640 - val_accuracy: 0.4737\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.2477 - accuracy: 0.4286 - val_loss: 1.4099 - val_accuracy: 0.3684\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.0675 - accuracy: 0.5195 - val_loss: 1.4007 - val_accuracy: 0.3684\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.0239 - accuracy: 0.6104 - val_loss: 1.3613 - val_accuracy: 0.3684\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.8684 - accuracy: 0.7532 - val_loss: 1.3343 - val_accuracy: 0.4737\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.7595 - accuracy: 0.7532 - val_loss: 1.3466 - val_accuracy: 0.4737\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.7540 - accuracy: 0.6753 - val_loss: 1.4325 - val_accuracy: 0.5263\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.6273 - accuracy: 0.7922 - val_loss: 1.5347 - val_accuracy: 0.5789\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.4916 - accuracy: 0.8052 - val_loss: 1.5593 - val_accuracy: 0.5789\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 15s 5s/step - loss: 0.4023 - accuracy: 0.8961 - val_loss: 1.5362 - val_accuracy: 0.4211\n",
      "Training for fold 4 ...\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.6114 - accuracy: 0.2208 - val_loss: 1.3844 - val_accuracy: 0.3684\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4631 - accuracy: 0.9091 - val_loss: 1.4767 - val_accuracy: 0.3684\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2485 - accuracy: 0.9870 - val_loss: 1.2926 - val_accuracy: 0.4737\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.1349 - accuracy: 0.9870 - val_loss: 1.2748 - val_accuracy: 0.4211\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0836 - accuracy: 1.0000 - val_loss: 1.3823 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 1.4393 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.4472 - val_accuracy: 0.3158\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.4569 - val_accuracy: 0.3684\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 1.4821 - val_accuracy: 0.3684\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.5166 - val_accuracy: 0.3684\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 22s 6s/step - loss: 1.4334 - accuracy: 0.2597 - val_loss: 1.7209 - val_accuracy: 0.2105\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.2022 - accuracy: 0.5065 - val_loss: 1.4665 - val_accuracy: 0.2632\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 1.0331 - accuracy: 0.5974 - val_loss: 1.4414 - val_accuracy: 0.2105\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.8891 - accuracy: 0.6494 - val_loss: 1.5371 - val_accuracy: 0.2632\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.8752 - accuracy: 0.7013 - val_loss: 1.5029 - val_accuracy: 0.2105\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.7013 - accuracy: 0.7273 - val_loss: 1.5200 - val_accuracy: 0.3158\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.6306 - accuracy: 0.7922 - val_loss: 1.7152 - val_accuracy: 0.2105\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.4501 - accuracy: 0.8571 - val_loss: 1.8305 - val_accuracy: 0.2632\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.4533 - accuracy: 0.8571 - val_loss: 1.8400 - val_accuracy: 0.2632\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 15s 5s/step - loss: 0.3606 - accuracy: 0.8831 - val_loss: 1.9583 - val_accuracy: 0.1579\n",
      "Training for fold 5 ...\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 10s 3s/step - loss: 1.5660 - accuracy: 0.2468 - val_loss: 1.7743 - val_accuracy: 0.3158\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4884 - accuracy: 0.8701 - val_loss: 1.4335 - val_accuracy: 0.3684\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2500 - accuracy: 0.9610 - val_loss: 1.6099 - val_accuracy: 0.2632\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.1321 - accuracy: 1.0000 - val_loss: 1.9652 - val_accuracy: 0.2632\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0784 - accuracy: 1.0000 - val_loss: 1.9866 - val_accuracy: 0.2632\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.9965 - val_accuracy: 0.2632\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 2.0836 - val_accuracy: 0.2632\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 2.2422 - val_accuracy: 0.2632\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.4029 - val_accuracy: 0.2632\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 12s 5s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.5163 - val_accuracy: 0.2632\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 31s 8s/step - loss: 1.4225 - accuracy: 0.2468 - val_loss: 1.5399 - val_accuracy: 0.2105\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 23s 8s/step - loss: 1.2388 - accuracy: 0.4416 - val_loss: 1.6640 - val_accuracy: 0.2105\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 24s 9s/step - loss: 1.0289 - accuracy: 0.6104 - val_loss: 1.4985 - val_accuracy: 0.2105\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 22s 8s/step - loss: 0.8995 - accuracy: 0.6623 - val_loss: 1.3804 - val_accuracy: 0.3684\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 21s 7s/step - loss: 0.8643 - accuracy: 0.6883 - val_loss: 1.4421 - val_accuracy: 0.3684\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 21s 8s/step - loss: 0.7324 - accuracy: 0.7532 - val_loss: 1.7231 - val_accuracy: 0.2105\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.6687 - accuracy: 0.7273 - val_loss: 1.9023 - val_accuracy: 0.1579\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 25s 9s/step - loss: 0.6335 - accuracy: 0.7403 - val_loss: 1.6933 - val_accuracy: 0.0526\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.5214 - accuracy: 0.8182 - val_loss: 1.6711 - val_accuracy: 0.2632\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 20s 7s/step - loss: 0.3928 - accuracy: 0.9221 - val_loss: 1.8025 - val_accuracy: 0.1579\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-Fold Cross-validation\n",
    "fold_no = 1\n",
    "for train, val in kfold.split(cross_train_X_norm, cross_train_labels_cat):\n",
    "    # Build models for each fold\n",
    "    model_gru_cross = build_gru_model(cross_train_X_norm.shape[1:], 4)\n",
    "    model_advanced_gru_cross = build_advanced_gru_model_with_attention(cross_train_X_norm.shape[1:], 4)\n",
    "    \n",
    "    # Training\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history_gru_cross = model_gru_cross.fit(cross_train_X_norm[train], cross_train_labels_cat[train], epochs=10, batch_size=32, validation_data=(cross_train_X_norm[val], cross_train_labels_cat[val]))\n",
    "    history_advanced_gru_cross = model_advanced_gru_cross.fit(cross_train_X_norm[train], cross_train_labels_cat[train], epochs=10, batch_size=32, validation_data=(cross_train_X_norm[val], cross_train_labels_cat[val]))\n",
    "    \n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6cf0900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 3.0060 - accuracy: 0.2500\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.3895 - accuracy: 0.5000\n",
      "Standard GRU Model Performance: [3.005998373031616, 0.25]\n",
      "Advanced GRU Model with Attention Performance: [1.3895056247711182, 0.5]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "performance_gru = model_gru_cross.evaluate(cross_test_X_norm, cross_test_labels_cat)\n",
    "performance_advanced_gru = model_advanced_gru_cross.evaluate(cross_test_X_norm, cross_test_labels_cat)\n",
    "\n",
    "print(\"Standard GRU Model Performance:\", performance_gru)\n",
    "print(\"Advanced GRU Model with Attention Performance:\", performance_advanced_gru)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
