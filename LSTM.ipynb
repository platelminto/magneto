{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using {}.\".format(device.type))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYgmSx-cB3hj",
        "outputId": "d6b743bb-717a-4762-90cf-7a7a20a96517"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "LOCAL_RUNTIME = False\n",
        "\n",
        "if not LOCAL_RUNTIME:\n",
        "    from google.colab import drive\n",
        "    data_dir = Path(\"/content/Data/\")\n",
        "\n",
        "    if not (data_dir.is_dir() and any(data_dir.iterdir())):\n",
        "        drive.mount('/content/drive/')\n",
        "\n",
        "        if not data_dir.is_dir():\n",
        "            !mkdir /content/Data/\n",
        "\n",
        "        intra_dir = data_dir / \"Intra\"\n",
        "        cross_dir = data_dir / \"Cross\"\n",
        "\n",
        "        if not (\n",
        "            intra_dir.is_dir()\n",
        "            and any(subdir.is_file() for subdir in intra_dir.iterdir())\n",
        "            and cross_dir.is_dir()\n",
        "            and any(subdir.is_file() for subdir in cross_dir.iterdir())\n",
        "        ):\n",
        "            !unzip '/content/drive/MyDrive/Data/DL/Intra.zip' -d '/content/Data/' > /dev/null\n",
        "            !unzip '/content/drive/MyDrive/Data/DL/Cross.zip' -d '/content/Data/' > /dev/null\n",
        "\n",
        "        drive.flush_and_unmount()\n",
        "else:\n",
        "    raise ValueError(\"This code is intended to run in Google Colab. Please switch to a Colab environment.\")\n",
        "\n",
        "assert data_dir.is_dir()\n"
      ],
      "metadata": {
        "id": "tqg2mWyjB-i-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eebed7c-9455-4b2c-fee8-c74c3a189e70"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "g1wCLdJr-eIR"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries\n",
        "import h5py\n",
        "import numpy as np\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Dropout, TimeDistributed\n",
        "\n",
        "data_dir = Path(\"./Data/\")\n",
        "intra_dir = data_dir / \"Intra\"\n",
        "cross_dir = data_dir / \"Cross\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_h5(path):\n",
        "    with h5py.File(path, 'r') as f:\n",
        "        keys = list(f.keys())\n",
        "        assert len(keys) == 1, \"Only one key per file is expected\"\n",
        "        matrix = f[keys[0]][()]\n",
        "    return matrix\n",
        "\n",
        "def load_labels(path: Path) -> np.ndarray:\n",
        "    *task, subject_identifier, chunk = path.stem.split(\"_\")\n",
        "    if \"rest\" in task:\n",
        "        y = 0\n",
        "    elif 'math' in task:\n",
        "        y = 1\n",
        "    elif 'working' in task:\n",
        "        y = 2\n",
        "    elif 'motor' in task:\n",
        "        y = 3\n",
        "    else:\n",
        "        assert False, 'unknown task'\n",
        "    return np.array([y, int(subject_identifier), int(chunk)])"
      ],
      "metadata": {
        "id": "SSw-6tB4-peG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def downsample(data, old_freq, new_freq):\n",
        "    # Calculate the downsampling factor\n",
        "    downsample_factor = int(np.round(old_freq / new_freq))\n",
        "    # Ensure that timesteps are divisible by the downsampling factor\n",
        "    data = data[:,:,:data.shape[2]//downsample_factor*downsample_factor]\n",
        "    # Reshape\n",
        "    reshaped_data = data.reshape(data.shape[0], data.shape[1], -1, downsample_factor)\n",
        "    # Take the mean along the last axis\n",
        "    downsampled_data = reshaped_data.mean(axis=-1)\n",
        "    return downsampled_data\n",
        "\n",
        "def z_score_normalize(data):\n",
        "    # Convert to PyTorch tensor\n",
        "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
        "    # Calculate mean and std along the timesteps\n",
        "    mean = torch.mean(data_tensor, dim=2, keepdim=True)\n",
        "    std = torch.std(data_tensor, dim=2, keepdim=True)\n",
        "    # Perform z-score norm\n",
        "    normalized_data = (data_tensor - mean) / std\n",
        "    return normalized_data"
      ],
      "metadata": {
        "id": "sUhai2Ny-pnp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## INTRA Data Loading and Preprocessing\n",
        "\n",
        "intra_train_glob = list((intra_dir / \"train\").glob(\"*.h5\"))\n",
        "intra_test_glob = list((intra_dir / \"test\").glob(\"*.h5\"))\n",
        "\n",
        "intra_train_X = np.stack([load_h5(path) for path in intra_train_glob])\n",
        "intra_train_labels = np.array([load_labels(path)[0] for path in intra_train_glob])\n",
        "intra_test_X = np.stack([load_h5(path) for path in intra_test_glob])\n",
        "intra_test_labels = np.array([load_labels(path)[0] for path in intra_test_glob])"
      ],
      "metadata": {
        "id": "9RsquYjX-wvA"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "intra_train_X_downsampled = downsample(intra_train_X, 2034, 125)\n",
        "intra_train_X_norm = z_score_normalize(intra_train_X_downsampled)\n",
        "\n",
        "intra_test_X_downsampled = downsample(intra_test_X, 2034, 125)\n",
        "intra_test_X_norm = z_score_normalize(intra_test_X_downsampled)\n",
        "\n",
        "del intra_train_X, intra_test_X, intra_train_X_downsampled, intra_test_X_downsampled\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "Xckvaab--zN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a41eeb-d85c-4cdb-bd90-28d476a74d01"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63569"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "intra_train_X_preprocessed = intra_train_X_norm.numpy()\n",
        "intra_train_X_preprocessed.shape\n",
        "intra_test_X_preprocessed = intra_test_X_norm.numpy()\n",
        "intra_test_X_preprocessed.shape"
      ],
      "metadata": {
        "id": "xACyRoCh-3aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd852ea3-aef0-4b92-c400-a76980aada1d"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 248, 2226)"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "intra_train_labels_one_hot = to_categorical(intra_train_labels, num_classes)\n",
        "intra_test_labels_one_hot = to_categorical(intra_test_labels, num_classes)\n",
        "\n",
        "del intra_train_labels, intra_test_labels\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "yGGyOHl0-6eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f51183d-1b3b-4355-9b1c-2d6dc015b747"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7206"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "zLUkIa1HPCnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape=input_shape, return_sequences=True))\n",
        "    Dropout(0.5),\n",
        "    model.add(LSTM(256))\n",
        "    Dropout(0.5),\n",
        "    model.add(Dense(4, activation='softmax'))  # 4 classes\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "H68_rQ7w_d8i"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "1hCC1g7p_o_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "gn7eQGpJ_oP6"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KFold\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "KJNMKOGW_xbs"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_no = 1\n",
        "for train, val in kfold.split(intra_train_X_preprocessed, intra_train_labels_one_hot):\n",
        "    # Build models for each fold\n",
        "    model_lstm = build_lstm_model(intra_train_X_preprocessed.shape[1:], 4)\n",
        "\n",
        "    # Training\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    history_lstm = model_lstm.fit(intra_train_X_preprocessed[train], intra_train_labels_one_hot[train], epochs=10, batch_size=32, validation_data=(intra_train_X_preprocessed[val], intra_train_labels_one_hot[val]))\n",
        "\n",
        "    fold_no += 1"
      ],
      "metadata": {
        "id": "3iNy8qTb_0r2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dbf81f-a0c8-4234-90e3-39d3a7449d21"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3616 - accuracy: 0.3200 - val_loss: 1.4950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.4522 - accuracy: 1.0000 - val_loss: 1.6676 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.1416 - accuracy: 1.0000 - val_loss: 1.8602 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 2.0854 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.3321 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5820 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.8296 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0722 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3041 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 8.7428e-04 - accuracy: 1.0000 - val_loss: 3.5202 - val_accuracy: 0.0000e+00\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3401 - accuracy: 0.3200 - val_loss: 1.5552 - val_accuracy: 0.2857\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.4229 - accuracy: 0.9600 - val_loss: 1.6294 - val_accuracy: 0.4286\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1288 - accuracy: 1.0000 - val_loss: 1.7161 - val_accuracy: 0.4286\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.8154 - val_accuracy: 0.4286\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.9355 - val_accuracy: 0.4286\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.0864 - val_accuracy: 0.4286\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.2631 - val_accuracy: 0.4286\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.4524 - val_accuracy: 0.4286\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 9.9258e-04 - accuracy: 1.0000 - val_loss: 2.6480 - val_accuracy: 0.4286\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 6.5915e-04 - accuracy: 1.0000 - val_loss: 2.8472 - val_accuracy: 0.4286\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3878 - accuracy: 0.2692 - val_loss: 1.8668 - val_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.4650 - accuracy: 0.9231 - val_loss: 1.9696 - val_accuracy: 0.1667\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1451 - accuracy: 1.0000 - val_loss: 2.0933 - val_accuracy: 0.1667\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 2.3217 - val_accuracy: 0.1667\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 2.6172 - val_accuracy: 0.1667\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.9334 - val_accuracy: 0.1667\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.2540 - val_accuracy: 0.1667\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.5695 - val_accuracy: 0.1667\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8719 - val_accuracy: 0.1667\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 8.9845e-04 - accuracy: 1.0000 - val_loss: 4.1570 - val_accuracy: 0.1667\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3381 - accuracy: 0.3846 - val_loss: 1.3019 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.4744 - accuracy: 0.9615 - val_loss: 1.2845 - val_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1541 - accuracy: 1.0000 - val_loss: 1.1930 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 1.1250 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.1054 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.1891 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.2707 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.3660 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 8.9775e-04 - accuracy: 1.0000 - val_loss: 1.4680 - val_accuracy: 0.5000\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 4s 4s/step - loss: 1.3699 - accuracy: 0.2692 - val_loss: 1.7561 - val_accuracy: 0.1667\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.5007 - accuracy: 0.8462 - val_loss: 1.7589 - val_accuracy: 0.1667\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 1.8841 - val_accuracy: 0.3333\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0678 - accuracy: 1.0000 - val_loss: 2.1105 - val_accuracy: 0.1667\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 2.3996 - val_accuracy: 0.1667\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.7077 - val_accuracy: 0.1667\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.0098 - val_accuracy: 0.1667\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.2951 - val_accuracy: 0.1667\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.5587 - val_accuracy: 0.1667\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.7988 - val_accuracy: 0.1667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "performance_lstm = model_lstm.evaluate(intra_test_X_preprocessed, intra_test_labels_one_hot)\n",
        "print(\"Standard LSTM Model Performance:\", performance_lstm)"
      ],
      "metadata": {
        "id": "BqcnWGTd_7XG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85556035-1abd-4fef-887c-c55e5081b0a8"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1094 - accuracy: 0.3750\n",
            "Standard LSTM Model Performance: [2.1094112396240234, 0.375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Data"
      ],
      "metadata": {
        "id": "HPNKaj4_NqvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#del intra_train_X_norm, intra_test_X_norm, intra_train_labels, intra_test_labels, intra_train_labels_one_hot, intra_test_labels_one_hot\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "HnEGmbyCPqNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615d8eb3-de69-4450-e548-e0f523db777d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74098"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_train_glob = list((cross_dir / \"train\").glob(\"*.h5\")) + list((cross_dir / \"test1\").glob(\"*.h5\")) + list((cross_dir / \"test2\").glob(\"*.h5\"))\n",
        "cross_test_glob = list((cross_dir / \"test3\").glob(\"*.h5\"))"
      ],
      "metadata": {
        "id": "vcr_mujhR3Rj"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_train_X = np.stack([load_h5(path) for path in cross_train_glob])\n",
        "cross_train_labels = np.array([load_labels(path)[0] for path in cross_train_glob])\n",
        "\n",
        "cross_test_X = np.stack([load_h5(path) for path in cross_test_glob])\n",
        "cross_test_labels = np.array([load_labels(path)[0] for path in cross_test_glob])"
      ],
      "metadata": {
        "id": "nLZZ-0nvN23y"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Cross data\n",
        "cross_train_X_downsampled = downsample(cross_train_X, 2034, 125)\n",
        "cross_train_X_norm = z_score_normalize(cross_train_X_downsampled)\n",
        "\n",
        "cross_test_X_downsampled = downsample(cross_test_X, 2034, 125)\n",
        "cross_test_X_norm = z_score_normalize(cross_test_X_downsampled)\n",
        "\n",
        "del cross_train_X, cross_test_X, cross_train_X_downsampled, cross_test_X_downsampled\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "JwaJqSIfOEVA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bde249e-505d-478d-db0f-8391a09b82ce"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_train_X_norm = cross_train_X_norm.numpy()\n",
        "cross_test_X_norm = cross_test_X_norm.numpy()"
      ],
      "metadata": {
        "id": "LjLqA06MOK-i"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to categorical\n",
        "cross_train_labels_cat = to_categorical(cross_train_labels)\n",
        "cross_test_labels_cat = to_categorical(cross_test_labels)"
      ],
      "metadata": {
        "id": "lEcgv6dbOSdW"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_folds = 5\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-Fold Cross-validation\n",
        "fold_no = 1\n",
        "for train, val in kfold.split(cross_train_X_norm, cross_train_labels_cat):\n",
        "    # Build models for each fold\n",
        "    model_lstm_cross = build_lstm_model(cross_train_X_norm.shape[1:], 4)\n",
        "\n",
        "    # Training\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    history_lstm_cross = model_lstm_cross.fit(cross_train_X_norm[train], cross_train_labels_cat[train], epochs=10, batch_size=32, validation_data=(cross_train_X_norm[val], cross_train_labels_cat[val]))\n",
        "\n",
        "    fold_no += 1"
      ],
      "metadata": {
        "id": "iXzHw-im_-7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cbe2380-a562-4fcc-f78e-e0993a4f0f9f"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 509ms/step - loss: 1.4345 - accuracy: 0.3289 - val_loss: 1.5739 - val_accuracy: 0.3000\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5426 - accuracy: 0.8553 - val_loss: 1.6296 - val_accuracy: 0.2000\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.2386 - accuracy: 0.9605 - val_loss: 1.5728 - val_accuracy: 0.2000\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 1.7994 - val_accuracy: 0.3000\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 2.3475 - val_accuracy: 0.2000\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.5717 - val_accuracy: 0.2000\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.0584 - val_accuracy: 0.2500\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.5963 - val_accuracy: 0.2500\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 6.1897e-04 - accuracy: 1.0000 - val_loss: 3.8840 - val_accuracy: 0.2500\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 4.5979e-04 - accuracy: 1.0000 - val_loss: 4.0692 - val_accuracy: 0.2500\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 524ms/step - loss: 1.4409 - accuracy: 0.2208 - val_loss: 1.4903 - val_accuracy: 0.3158\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.5029 - accuracy: 0.9740 - val_loss: 1.5064 - val_accuracy: 0.4737\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.2044 - accuracy: 0.9740 - val_loss: 1.7374 - val_accuracy: 0.2632\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0488 - accuracy: 1.0000 - val_loss: 2.4389 - val_accuracy: 0.2632\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.6519 - val_accuracy: 0.2632\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.7728 - val_accuracy: 0.2632\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.8891 - val_accuracy: 0.2632\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.1695 - val_accuracy: 0.3158\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 6.0112e-04 - accuracy: 1.0000 - val_loss: 3.4729 - val_accuracy: 0.2632\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 4.5813e-04 - accuracy: 1.0000 - val_loss: 3.7201 - val_accuracy: 0.2105\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 492ms/step - loss: 1.4226 - accuracy: 0.1948 - val_loss: 1.5639 - val_accuracy: 0.2105\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.4944 - accuracy: 0.9610 - val_loss: 1.4469 - val_accuracy: 0.3684\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.1595 - accuracy: 1.0000 - val_loss: 2.0324 - val_accuracy: 0.1579\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.1579\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.8181 - val_accuracy: 0.1579\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.8458 - val_accuracy: 0.1579\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9101 - val_accuracy: 0.1053\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 9.3725e-04 - accuracy: 1.0000 - val_loss: 3.0225 - val_accuracy: 0.1579\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 5.3357e-04 - accuracy: 1.0000 - val_loss: 3.1762 - val_accuracy: 0.1579\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 3.9470e-04 - accuracy: 1.0000 - val_loss: 3.3376 - val_accuracy: 0.1579\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 498ms/step - loss: 1.4503 - accuracy: 0.2078 - val_loss: 1.3578 - val_accuracy: 0.2632\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.5222 - accuracy: 0.9610 - val_loss: 1.5765 - val_accuracy: 0.2632\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.1824 - accuracy: 1.0000 - val_loss: 1.7135 - val_accuracy: 0.3684\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 1.9176 - val_accuracy: 0.4737\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.2563 - val_accuracy: 0.4211\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.6386 - val_accuracy: 0.3684\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0617 - val_accuracy: 0.2632\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 8.5969e-04 - accuracy: 1.0000 - val_loss: 3.4656 - val_accuracy: 0.2105\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 4.8533e-04 - accuracy: 1.0000 - val_loss: 3.8106 - val_accuracy: 0.2105\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 3.2811e-04 - accuracy: 1.0000 - val_loss: 4.0879 - val_accuracy: 0.2105\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 4s 489ms/step - loss: 1.4375 - accuracy: 0.2078 - val_loss: 1.4665 - val_accuracy: 0.1053\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.4877 - accuracy: 0.9610 - val_loss: 1.3579 - val_accuracy: 0.3158\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 0.1760 - accuracy: 1.0000 - val_loss: 1.5939 - val_accuracy: 0.2105\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 2.0087 - val_accuracy: 0.2632\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.3892 - val_accuracy: 0.3158\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.9925 - val_accuracy: 0.3158\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.3898 - val_accuracy: 0.3158\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 8.6218e-04 - accuracy: 1.0000 - val_loss: 3.7756 - val_accuracy: 0.2105\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 5.2221e-04 - accuracy: 1.0000 - val_loss: 4.1815 - val_accuracy: 0.2105\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 3.9219e-04 - accuracy: 1.0000 - val_loss: 4.4644 - val_accuracy: 0.2105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "performance_lstm = model_lstm_cross.evaluate(cross_test_X_norm, cross_test_labels_cat)\n",
        "print(\"Standard LSTM Model Performance:\", performance_lstm)"
      ],
      "metadata": {
        "id": "60ZuD84oACw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab27ede-4fad-4020-cdd3-0b73df798c4a"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step - loss: 3.2539 - accuracy: 0.5000\n",
            "Standard LSTM Model Performance: [3.253880500793457, 0.5]\n"
          ]
        }
      ]
    }
  ]
}